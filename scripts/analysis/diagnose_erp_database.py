#!/usr/bin/env python3
"""
ERP DATABASE DIAGNOSTIC — A Consultant's Engagement Workbook.

52 questions organized across 10 sections probing data validity and utility
from the perspective of veteran SC consultants using SCOR-DS, Desmet's
Triangle, and Mentzer's SC models.

Connects via psycopg2 to a PostgreSQL database containing 36 normalized tables
(~368M rows) generated by scripts/erp/ from Prism Sim output.

Sections:
  0. Data Landscape (5 Qs)              — Table census, date range, topology
  1. Physical-Financial Reconciliation  — GL balance, COGS/Rev, invoice integrity
  2. SCOR Source Process (7 Qs)         — Procurement chain, HHI, 3-way match
  3. SCOR Make Process (7 Qs)           — WO→Batch, yield, BOM integrity
  4. SCOR Deliver Process (7 Qs)        — Shipments, fill rate, freight coverage
  5. SCOR Return Process (4 Qs)         — Return rates, disposition, GL recon
  6. Desmet's Triangle (7 Qs)           — Service/Cost/Cash trade-off metrics
  7. Temporal & Causal Integrity (6 Qs) — Sequence monotonicity, date ordering
  8. Friction Layer Audit (7 Qs)        — Controlled noise at expected rates
  9. Digital Thread & Traceability (5 Qs) — reference_id, node_id, end-to-end

Usage:
    poetry run python scripts/analysis/diagnose_erp_database.py
    poetry run python scripts/analysis/diagnose_erp_database.py --section 6
    poetry run python scripts/analysis/diagnose_erp_database.py --connection "postgresql://..."

v0.79.0
"""

# ruff: noqa: E501, PLR2004
from __future__ import annotations

import argparse
import io
import sys
import time
from datetime import datetime

import psycopg2

WIDTH = 78


def _f(val: object) -> float:
    """Coerce a psycopg2 Decimal/int/None to float for arithmetic."""
    if val is None:
        return 0.0
    return float(val)  # type: ignore[arg-type]

# ═══════════════════════════════════════════════════════════════════════════════
# Expected friction rates (from scripts/erp/config.py defaults)
# ═══════════════════════════════════════════════════════════════════════════════

EXPECTED_FRICTION = {
    "duplicate_supplier_rate": 0.10,
    "sku_rename_rate": 0.05,
    "price_variance_rate": 0.08,
    "qty_variance_rate": 0.05,
    "null_fk_rate_ap": 0.02,
    "null_fk_rate_gl": 0.01,
    "duplicate_invoice_rate": 0.005,
    "status_inconsistency_rate": 0.03,
    "bad_debt_rate": 0.005,
    "early_discount_rate": 0.10,
}

EXPECTED_COA = {
    "1000", "1100", "1120", "1130", "1140", "1200",
    "2100", "4100", "4200", "5100", "5200", "5300", "5400", "5500",
}

DPO_TARGET = 45.0


# ═══════════════════════════════════════════════════════════════════════════════
# Output helpers (mirrors diagnose_supply_chain.py formatting)
# ═══════════════════════════════════════════════════════════════════════════════

def _section_header(num: int, title: str) -> None:
    print(f"\n{'=' * WIDTH}")
    print(f"  SECTION {num}: {title}".center(WIDTH))
    print(f"{'=' * WIDTH}")


def _q_header(qid: str, title: str) -> None:
    print(f"\n{'─' * WIDTH}")
    print(f"  {qid}. {title}")
    print(f"{'─' * WIDTH}")


def _kpi_row(name: str, actual: str, target: str, status: str) -> None:
    light = {"PASS": "PASS  ", "WARN": "WARN  ", "FAIL": "FAIL  "}.get(status, status)
    print(f"  {name:<30}  {actual:>14}  {target:>14}  {light:>6}")


def _traffic(val: object, green_lo: float, green_hi: float,
             yellow_lo: float = float("-inf"), yellow_hi: float = float("inf")) -> str:
    v = float(val)  # type: ignore[arg-type]
    if green_lo <= v <= green_hi:
        return "PASS"
    if yellow_lo <= v <= yellow_hi:
        return "WARN"
    return "FAIL"


def _friction_verdict(actual_rate: object, expected_rate: float, tol: float = 0.02) -> str:
    """Compare an actual friction rate against the expected config rate (+-tol)."""
    a = float(actual_rate)  # type: ignore[arg-type]
    if abs(a - expected_rate) <= tol:
        return "PASS"
    if abs(a - expected_rate) <= tol * 2:
        return "WARN"
    return "FAIL"


def _pct(num: object, den: object) -> float:
    n, d = float(num), float(den)  # type: ignore[arg-type]
    return (n / d * 100.0) if d > 0 else 0.0


def _fmt_money(val: object) -> str:
    v = float(val)  # type: ignore[arg-type]
    if abs(v) >= 1e9:
        return f"${v / 1e9:,.2f}B"
    if abs(v) >= 1e6:
        return f"${v / 1e6:,.2f}M"
    if abs(v) >= 1e3:
        return f"${v / 1e3:,.1f}K"
    return f"${v:,.2f}"


def _verdict_counts(p: int = 0, w: int = 0, f: int = 0) -> dict[str, int]:
    return {"pass": p, "warn": w, "fail": f}


def _merge(a: dict[str, int], b: dict[str, int]) -> dict[str, int]:
    return {"pass": a["pass"] + b["pass"], "warn": a["warn"] + b["warn"], "fail": a["fail"] + b["fail"]}


# ═══════════════════════════════════════════════════════════════════════════════
# Section 0: Data Landscape
# ═══════════════════════════════════════════════════════════════════════════════

def run_section0(conn: psycopg2.extensions.connection) -> dict[str, int]:
    """SECTION 0: Data Landscape (Q0.1-Q0.5)."""
    _section_header(0, "DATA LANDSCAPE")
    counts = _verdict_counts()

    # Q0.1 — Table Census
    _q_header("Q0.1", "Table Census — all 36 tables present & populated?")
    with conn.cursor() as cur:
        cur.execute("""
            SELECT relname, n_live_tup
            FROM pg_stat_user_tables
            WHERE schemaname = 'public'
            ORDER BY relname
        """)
        rows = cur.fetchall()

    table_count = len(rows)
    empty_tables = [r[0] for r in rows if r[1] == 0]
    print(f"  Tables found: {table_count}")
    print(f"  {'Table':<35} {'Est. Rows':>14}")
    print(f"  {'─' * 35} {'─' * 14}")
    for name, est_rows in rows:
        flag = " *EMPTY*" if est_rows == 0 else ""
        print(f"  {name:<35} {est_rows:>14,}{flag}")

    if table_count >= 36 and len(empty_tables) == 0:
        v = "PASS"
    elif table_count >= 36:
        v = "WARN"
    else:
        v = "FAIL"
    print(f"\n  Verdict: {v} ({table_count} tables, {len(empty_tables)} empty)")
    counts[v.lower()] += 1

    # Q0.2 — Date Range Coverage
    _q_header("Q0.2", "Date Range Coverage — consistent 365-day span?")
    date_tables = [
        ("orders", "day"),
        ("shipments", "ship_date"),
        ("batches", "production_date"),
        ("gl_journal", "entry_date"),
    ]
    all_ok = True
    for tbl, col in date_tables:
        with conn.cursor() as cur:
            cur.execute(f"SELECT MIN({col}), MAX({col}), COUNT(DISTINCT {col}) FROM {tbl}")
            lo, hi, distinct_days = cur.fetchone()
        span = hi - lo + 1 if lo is not None and hi is not None else 0
        ok = 350 <= span <= 500  # 365 + buffer for bad_debt writeoff (day+90)
        if not ok:
            all_ok = False
        status = "OK" if ok else "SHORT"
        print(f"  {tbl}.{col}: day {lo}-{hi} (span={span}, distinct={distinct_days}) [{status}]")

    v = "PASS" if all_ok else "FAIL"
    print(f"  Verdict: {v}")
    counts[v.lower()] += 1

    # Q0.3 — Master Data Completeness
    _q_header("Q0.3", "Master Data Completeness — nulls in critical columns?")
    master_checks = [
        ("suppliers", "name"),
        ("skus", "name"),
        ("plants", "city"),
        ("ingredients", "category"),
    ]
    all_ok = True
    for tbl, col in master_checks:
        with conn.cursor() as cur:
            cur.execute(f"SELECT COUNT(*), COUNT(CASE WHEN {col} IS NULL THEN 1 END) FROM {tbl}")
            total, nulls = cur.fetchone()
        null_pct = _pct(nulls, total)
        ok = null_pct < 1.0
        if not ok:
            all_ok = False
        print(f"  {tbl}.{col}: {nulls}/{total} null ({null_pct:.2f}%) [{'OK' if ok else 'HIGH'}]")

    v = "PASS" if all_ok else "FAIL"
    print(f"  Verdict: {v}")
    counts[v.lower()] += 1

    # Q0.4 — Network Topology
    _q_header("Q0.4", "Network Topology — expected scale?")
    with conn.cursor() as cur:
        cur.execute("SELECT COUNT(*) FROM plants")
        n_plants = cur.fetchone()[0]
        cur.execute("SELECT COUNT(*) FROM distribution_centers")
        n_dcs = cur.fetchone()[0]
        cur.execute("SELECT COUNT(*) FROM retail_locations")
        n_stores = cur.fetchone()[0]
        cur.execute("SELECT COUNT(*) FROM suppliers")
        n_suppliers = cur.fetchone()[0]
        cur.execute("SELECT COUNT(*) FROM skus")
        n_skus = cur.fetchone()[0]

    print(f"  Plants:     {n_plants:>6}")
    print(f"  DCs:        {n_dcs:>6}")
    print(f"  Stores:     {n_stores:>6}")
    print(f"  Suppliers:  {n_suppliers:>6}")
    print(f"  SKUs:       {n_skus:>6}")

    # Plants 4-6 (base; friction duplicates can push higher), stores >3500, SKUs >400
    ok = n_plants >= 4 and n_stores > 3500 and n_skus > 400
    v = "PASS" if ok else "FAIL"
    print(f"  Verdict: {v}")
    counts[v.lower()] += 1

    # Q0.5 — Chart of Accounts Integrity
    _q_header("Q0.5", "Chart of Accounts Integrity — all 14 accounts?")
    with conn.cursor() as cur:
        cur.execute("SELECT account_code, account_name, account_type FROM chart_of_accounts ORDER BY account_code")
        coa_rows = cur.fetchall()

    found_codes = {r[0] for r in coa_rows}
    missing = EXPECTED_COA - found_codes
    extra = found_codes - EXPECTED_COA
    print(f"  Accounts found: {len(found_codes)}")
    for code, name, atype in coa_rows:
        print(f"    {code}  {name:<35} ({atype})")
    if missing:
        print(f"  Missing: {missing}")
    if extra:
        print(f"  Extra: {extra}")

    v = "PASS" if not missing else "FAIL"
    print(f"  Verdict: {v}")
    counts[v.lower()] += 1

    return counts


# ═══════════════════════════════════════════════════════════════════════════════
# Section 1: Physical-Financial Reconciliation
# ═══════════════════════════════════════════════════════════════════════════════

def run_section1(conn: psycopg2.extensions.connection) -> dict[str, int]:
    """SECTION 1: Physical-Financial Reconciliation (Q1.1-Q1.7)."""
    _section_header(1, "PHYSICAL-FINANCIAL RECONCILIATION")
    counts = _verdict_counts()

    # Q1.1 — GL Global Balance
    _q_header("Q1.1", "GL Global Balance — SUM(debit) == SUM(credit)?")
    with conn.cursor() as cur:
        cur.execute("SELECT SUM(debit_amount), SUM(credit_amount) FROM gl_journal")
        total_dr, total_cr = cur.fetchone()

    diff = abs(_f(total_dr) - _f(total_cr))
    print(f"  Total Debits:  {_fmt_money(total_dr)}")
    print(f"  Total Credits: {_fmt_money(total_cr)}")
    print(f"  Imbalance:     ${diff:,.4f}")

    v = "PASS" if diff < 5.0 else "FAIL"
    _kpi_row("GL Imbalance", f"${diff:,.4f}", "<$5.00", v)
    counts[v.lower()] += 1

    # Q1.2 — GL Per-Day Balance
    _q_header("Q1.2", "GL Per-Day Balance — any day with >$0.10 imbalance?")
    with conn.cursor() as cur:
        cur.execute("""
            SELECT COUNT(*),
                   SUM(CASE WHEN ABS(dr - cr) > 0.10 THEN 1 ELSE 0 END)
            FROM (
                SELECT entry_date,
                       SUM(debit_amount) as dr,
                       SUM(credit_amount) as cr
                FROM gl_journal
                GROUP BY entry_date
            ) daily
        """)
        day_count, imbalanced_days = cur.fetchone()

    print(f"  Days with GL entries: {day_count}")
    print(f"  Days with imbalance > $0.10: {imbalanced_days}")

    v = "PASS" if imbalanced_days == 0 else "FAIL"
    _kpi_row("Imbalanced Days", str(imbalanced_days), "0", v)
    counts[v.lower()] += 1

    # Q1.3 — GL Account Type Balances
    _q_header("Q1.3", "GL Account Type Balances — net balance by type")
    with conn.cursor() as cur:
        cur.execute("""
            SELECT coa.account_type,
                   SUM(g.debit_amount) as total_dr,
                   SUM(g.credit_amount) as total_cr,
                   SUM(g.debit_amount) - SUM(g.credit_amount) as net
            FROM gl_journal g
            JOIN chart_of_accounts coa ON coa.account_code = g.account_code
            GROUP BY coa.account_type
            ORDER BY coa.account_type
        """)
        type_rows = cur.fetchall()

    print(f"  {'Type':<12} {'Debits':>14} {'Credits':>14} {'Net':>14}")
    print(f"  {'─' * 12} {'─' * 14} {'─' * 14} {'─' * 14}")
    for atype, dr, cr, net in type_rows:
        print(f"  {atype:<12} {_fmt_money(dr):>14} {_fmt_money(cr):>14} {_fmt_money(net):>14}")
    print("  (Informational — assets net debit, revenue/liability net credit)")
    # Informational, always counts as pass
    counts["pass"] += 1

    # Q1.4 — COGS-to-Revenue Ratio
    _q_header("Q1.4", "COGS-to-Revenue Ratio")
    with conn.cursor() as cur:
        cur.execute("""
            SELECT
                SUM(CASE WHEN account_code = '5100' THEN debit_amount ELSE 0 END) as cogs,
                SUM(CASE WHEN account_code = '4100' THEN credit_amount ELSE 0 END) as revenue
            FROM gl_journal
        """)
        cogs, revenue = cur.fetchone()

    ratio = (_f(cogs) / _f(revenue) * 100) if _f(revenue) > 0 else 0
    print(f"  COGS:    {_fmt_money(cogs)}")
    print(f"  Revenue: {_fmt_money(revenue)}")
    print(f"  Ratio:   {ratio:.1f}%")

    v = _traffic(ratio, 50, 80, 40, 90)
    _kpi_row("COGS/Revenue", f"{ratio:.1f}%", "50-80%", v)
    counts[v.lower()] += 1

    # Q1.5 — AP Invoice Header = Sum(Lines)
    _q_header("Q1.5", "AP Invoice Header = Sum(Lines)?")
    with conn.cursor() as cur:
        cur.execute("""
            SELECT COUNT(*),
                   SUM(CASE WHEN ABS(ai.total_amount - COALESCE(line_sum, 0)) > 0.01 THEN 1 ELSE 0 END)
            FROM ap_invoices ai
            LEFT JOIN (
                SELECT invoice_id, SUM(line_amount) as line_sum
                FROM ap_invoice_lines
                GROUP BY invoice_id
            ) ls ON ls.invoice_id = ai.id
        """)
        total_ap, mismatch_ap = cur.fetchone()

    mismatch_pct = _pct(mismatch_ap, total_ap)
    print(f"  AP invoices: {total_ap:,}")
    print(f"  Header/Lines mismatch: {mismatch_ap:,} ({mismatch_pct:.2f}%)")

    v = "PASS" if mismatch_pct < 0.1 else ("WARN" if mismatch_pct < 1.0 else "FAIL")
    _kpi_row("AP Mismatch Rate", f"{mismatch_pct:.2f}%", "<0.1%", v)
    counts[v.lower()] += 1

    # Q1.6 — AR Invoice Header = Sum(Lines)
    _q_header("Q1.6", "AR Invoice Header = Sum(Lines)?")
    with conn.cursor() as cur:
        cur.execute("""
            SELECT COUNT(*),
                   SUM(CASE WHEN ABS(ai.total_amount - COALESCE(line_sum, 0)) > 0.01 THEN 1 ELSE 0 END)
            FROM ar_invoices ai
            LEFT JOIN (
                SELECT invoice_id, SUM(line_amount) as line_sum
                FROM ar_invoice_lines
                GROUP BY invoice_id
            ) ls ON ls.invoice_id = ai.id
        """)
        total_ar, mismatch_ar = cur.fetchone()

    mismatch_pct = _pct(mismatch_ar, total_ar)
    print(f"  AR invoices: {total_ar:,}")
    print(f"  Header/Lines mismatch: {mismatch_ar:,} ({mismatch_pct:.2f}%)")

    v = "PASS" if mismatch_pct < 0.1 else ("WARN" if mismatch_pct < 1.0 else "FAIL")
    _kpi_row("AR Mismatch Rate", f"{mismatch_pct:.2f}%", "<0.1%", v)
    counts[v.lower()] += 1

    # Q1.7 — GL Account Activity Distribution
    _q_header("Q1.7", "GL Account Activity Distribution — all core accounts active?")
    with conn.cursor() as cur:
        cur.execute("""
            SELECT g.account_code, coa.account_name,
                   COUNT(*) as entries,
                   SUM(g.debit_amount) as total_dr,
                   SUM(g.credit_amount) as total_cr
            FROM gl_journal g
            JOIN chart_of_accounts coa ON coa.account_code = g.account_code
            GROUP BY g.account_code, coa.account_name
            ORDER BY g.account_code
        """)
        acct_rows = cur.fetchall()

    print(f"  {'Code':<6} {'Name':<30} {'Entries':>10} {'Debits':>14} {'Credits':>14}")
    print(f"  {'─' * 6} {'─' * 30} {'─' * 10} {'─' * 14} {'─' * 14}")
    active_codes = set()
    for code, name, entries, dr, cr in acct_rows:
        active_codes.add(code)
        print(f"  {code:<6} {name:<30} {entries:>10,} {_fmt_money(dr):>14} {_fmt_money(cr):>14}")

    core_accounts = {"1000", "1100", "1130", "1140", "1200", "2100", "4100", "5100", "5300"}
    missing_activity = core_accounts - active_codes
    v = "PASS" if not missing_activity else "FAIL"
    if missing_activity:
        print(f"  Missing activity: {missing_activity}")
    print(f"  Verdict: {v}")
    counts[v.lower()] += 1

    return counts


# ═══════════════════════════════════════════════════════════════════════════════
# Section 2: SCOR Source Process
# ═══════════════════════════════════════════════════════════════════════════════

def run_section2(conn: psycopg2.extensions.connection) -> dict[str, int]:
    """SECTION 2: SCOR Source Process (Q2.1-Q2.7)."""
    _section_header(2, "SCOR SOURCE PROCESS")
    counts = _verdict_counts()

    # Q2.1 — Procurement Chain Completeness
    _q_header("Q2.1", "Procurement Chain Completeness — PO -> GR -> AP ratios")
    with conn.cursor() as cur:
        cur.execute("SELECT COUNT(*) FROM purchase_orders")
        n_po = cur.fetchone()[0]
        cur.execute("SELECT COUNT(*) FROM goods_receipts")
        n_gr = cur.fetchone()[0]
        cur.execute("SELECT COUNT(*) FROM ap_invoices")
        n_ap = cur.fetchone()[0]
        cur.execute("SELECT COUNT(*) FROM ap_invoices WHERE gr_id IS NULL")
        n_ap_null_gr = cur.fetchone()[0]

    null_gr_rate = _pct(n_ap_null_gr, n_ap)
    print(f"  Purchase Orders: {n_po:,}")
    print(f"  Goods Receipts:  {n_gr:,}")
    print(f"  AP Invoices:     {n_ap:,}")
    print(f"  AP with null gr_id: {n_ap_null_gr:,} ({null_gr_rate:.1f}%)")

    # Expect ~2% null gr_id from friction
    v = _friction_verdict(null_gr_rate / 100, EXPECTED_FRICTION["null_fk_rate_ap"])
    _kpi_row("Null gr_id Rate", f"{null_gr_rate:.1f}%", f"~{EXPECTED_FRICTION['null_fk_rate_ap'] * 100:.0f}%", v)
    counts[v.lower()] += 1

    # Q2.2 — Supplier Concentration (HHI)
    _q_header("Q2.2", "Supplier Concentration (HHI) — monopoly risk?")
    with conn.cursor() as cur:
        cur.execute("""
            SELECT supplier_id, SUM(total_amount) as spend
            FROM ap_invoices
            WHERE supplier_id IS NOT NULL
            GROUP BY supplier_id
        """)
        spend_rows = cur.fetchall()

    total_spend = sum(_f(r[1]) for r in spend_rows)
    hhi = sum((_f(r[1]) / total_spend * 100) ** 2 for r in spend_rows) if total_spend > 0 else 0
    top5 = sorted(spend_rows, key=lambda r: r[1], reverse=True)[:5]

    print(f"  Total AP Spend: {_fmt_money(total_spend)}")
    print(f"  Unique Suppliers: {len(spend_rows)}")
    print(f"  HHI (Herfindahl): {hhi:.0f}")
    print("  Top 5 suppliers by spend:")
    for sid, sp in top5:
        print(f"    Supplier {sid}: {_fmt_money(sp)} ({_pct(sp, total_spend):.1f}%)")

    v = "PASS" if hhi < 1500 else ("WARN" if hhi < 2500 else "FAIL")
    _kpi_row("HHI", f"{hhi:.0f}", "<1500", v)
    counts[v.lower()] += 1

    # Q2.3 — Procurement Lead Time
    _q_header("Q2.3", "Procurement Lead Time — PO to GR")
    with conn.cursor() as cur:
        # Match POs to GRs via plant_id and date proximity
        cur.execute("""
            SELECT
                percentile_cont(0.50) WITHIN GROUP (ORDER BY gr.receipt_date - po.order_date),
                percentile_cont(0.05) WITHIN GROUP (ORDER BY gr.receipt_date - po.order_date),
                percentile_cont(0.95) WITHIN GROUP (ORDER BY gr.receipt_date - po.order_date),
                AVG(gr.receipt_date - po.order_date),
                COUNT(*)
            FROM purchase_orders po
            JOIN goods_receipts gr ON gr.plant_id = po.plant_id
                AND gr.receipt_date >= po.order_date
                AND gr.receipt_date <= po.order_date + 30
        """)
        p50, p05, p95, avg_lt, n_pairs = cur.fetchone()

    if p50 is not None:
        print(f"  Matched PO→GR pairs: {n_pairs:,}")
        print(f"  Lead time P5/P50/P95: {float(p05):.0f} / {float(p50):.0f} / {float(p95):.0f} days")
        print(f"  Mean: {float(avg_lt):.1f} days")
        v = "PASS" if 3 <= float(p50) <= 15 else "WARN"
    else:
        print("  No PO→GR matches found")
        v = "FAIL"
    _kpi_row("Median Lead Time", f"{float(p50 or 0):.0f}d", "3-15d", v)
    counts[v.lower()] += 1

    # Q2.4 — 3-Way Match Variance Analysis
    _q_header("Q2.4", "3-Way Match Variance Analysis")
    with conn.cursor() as cur:
        cur.execute("""
            SELECT variance_type, COUNT(*), AVG(ABS(variance_amount))
            FROM invoice_variances
            GROUP BY variance_type
        """)
        var_rows = cur.fetchall()

        cur.execute("SELECT COUNT(*) FROM ap_invoice_lines")
        n_ap_lines = cur.fetchone()[0]

    print(f"  AP Invoice Lines: {n_ap_lines:,}")
    all_var_ok = True
    for vtype, cnt, avg_amt in var_rows:
        rate = _pct(cnt, n_ap_lines)
        expected = EXPECTED_FRICTION.get(f"{vtype}_variance_rate", 0) * 100
        verdict = _friction_verdict(rate / 100, expected / 100)
        if verdict != "PASS":
            all_var_ok = False
        print(f"  {vtype}: {cnt:,} ({rate:.2f}%, expected ~{expected:.0f}%), avg variance ${float(avg_amt):,.2f} [{verdict}]")

    v = "PASS" if all_var_ok else "WARN"
    counts[v.lower()] += 1

    # Q2.5 — DPO Calculation
    _q_header("Q2.5", "DPO Calculation — Days Payable Outstanding")
    with conn.cursor() as cur:
        cur.execute("""
            SELECT AVG(p.payment_date - ai.invoice_date),
                   percentile_cont(0.50) WITHIN GROUP (ORDER BY p.payment_date - ai.invoice_date)
            FROM ap_payments p
            JOIN ap_invoices ai ON ai.id = p.invoice_id
        """)
        avg_dpo, p50_dpo = cur.fetchone()

    if avg_dpo is not None:
        print(f"  Average DPO: {float(avg_dpo):.1f} days")
        print(f"  Median DPO:  {float(p50_dpo):.1f} days")
        v = "PASS" if abs(float(avg_dpo) - DPO_TARGET) <= 10 else "WARN"
        _kpi_row("DPO", f"{float(avg_dpo):.1f}d", f"{DPO_TARGET:.0f}d +-10", v)
    else:
        print("  No AP payments found")
        v = "FAIL"
    counts[v.lower()] += 1

    # Q2.6 — Ingredient Coverage
    _q_header("Q2.6", "Ingredient Coverage — any ingredients without suppliers?")
    with conn.cursor() as cur:
        cur.execute("""
            SELECT COUNT(*) FROM ingredients i
            WHERE NOT EXISTS (
                SELECT 1 FROM supplier_ingredients si WHERE si.ingredient_id = i.id
            )
        """)
        orphan_ingredients = cur.fetchone()[0]
        cur.execute("SELECT COUNT(*) FROM ingredients")
        n_ingredients = cur.fetchone()[0]

    print(f"  Total ingredients: {n_ingredients}")
    print(f"  Without supplier: {orphan_ingredients}")

    v = "PASS" if orphan_ingredients == 0 else "FAIL"
    _kpi_row("Orphan Ingredients", str(orphan_ingredients), "0", v)
    counts[v.lower()] += 1

    # Q2.7 — GR vs AP Spend Consistency
    _q_header("Q2.7", "GR vs AP Spend Consistency")
    with conn.cursor() as cur:
        cur.execute("""
            SELECT SUM(grl.quantity_kg * i.cost_per_kg)
            FROM goods_receipt_lines grl
            JOIN ingredients i ON i.id = grl.ingredient_id
        """)
        gr_value = cur.fetchone()[0] or 0

        cur.execute("SELECT SUM(line_amount) FROM ap_invoice_lines")
        ap_value = cur.fetchone()[0] or 0

    ratio = (_f(ap_value) / _f(gr_value)) if _f(gr_value) > 0 else 0
    print(f"  GR Value (qty*cost_per_kg): {_fmt_money(gr_value)}")
    print(f"  AP Line Value:              {_fmt_money(ap_value)}")
    print(f"  AP/GR Ratio:                {ratio:.3f}")

    # Expect within 15% due to friction price/qty variances
    v = "PASS" if 0.85 <= ratio <= 1.15 else ("WARN" if 0.75 <= ratio <= 1.25 else "FAIL")
    _kpi_row("AP/GR Ratio", f"{ratio:.3f}", "0.85-1.15", v)
    counts[v.lower()] += 1

    return counts


# ═══════════════════════════════════════════════════════════════════════════════
# Section 3: SCOR Make Process
# ═══════════════════════════════════════════════════════════════════════════════

def run_section3(conn: psycopg2.extensions.connection) -> dict[str, int]:
    """SECTION 3: SCOR Make Process (Q3.1-Q3.7)."""
    _section_header(3, "SCOR MAKE PROCESS")
    counts = _verdict_counts()

    # Q3.1 — Work Order -> Batch Completeness
    _q_header("Q3.1", "Work Order -> Batch Completeness")
    with conn.cursor() as cur:
        cur.execute("SELECT COUNT(*) FROM work_orders")
        n_wo = cur.fetchone()[0]
        cur.execute("SELECT COUNT(*) FROM batches")
        n_batches = cur.fetchone()[0]
        cur.execute("SELECT COUNT(DISTINCT wo_id) FROM batches WHERE wo_id IS NOT NULL")
        n_wo_with_batch = cur.fetchone()[0]

    coverage = _pct(n_wo_with_batch, n_wo)
    print(f"  Work Orders: {n_wo:,}")
    print(f"  Batches:     {n_batches:,}")
    print(f"  WOs with >=1 batch: {n_wo_with_batch:,} ({coverage:.1f}%)")

    v = "PASS" if coverage > 90 else ("WARN" if coverage > 80 else "FAIL")
    _kpi_row("WO→Batch Coverage", f"{coverage:.1f}%", ">90%", v)
    counts[v.lower()] += 1

    # Q3.2 — Batch Ingredient Completeness
    _q_header("Q3.2", "Batch Ingredient Completeness")
    with conn.cursor() as cur:
        cur.execute("""
            SELECT COUNT(DISTINCT bi.batch_id) FROM batch_ingredients bi
        """)
        batches_with_ingredients = cur.fetchone()[0]

    coverage = _pct(batches_with_ingredients, n_batches)
    print(f"  Batches with ingredients: {batches_with_ingredients:,} / {n_batches:,} ({coverage:.1f}%)")

    v = "PASS" if coverage >= 99 else ("WARN" if coverage >= 95 else "FAIL")
    _kpi_row("Ingredient Coverage", f"{coverage:.1f}%", ">=99%", v)
    counts[v.lower()] += 1

    # Q3.3 — Yield Analysis
    _q_header("Q3.3", "Yield Analysis")
    with conn.cursor() as cur:
        cur.execute("""
            SELECT AVG(yield_percent),
                   STDDEV(yield_percent),
                   percentile_cont(0.05) WITHIN GROUP (ORDER BY yield_percent),
                   percentile_cont(0.95) WITHIN GROUP (ORDER BY yield_percent),
                   COUNT(CASE WHEN yield_percent > 100 THEN 1 END)
            FROM batches
            WHERE yield_percent IS NOT NULL
        """)
        avg_yield, std_yield, p05_yield, p95_yield, over_yield = cur.fetchone()

    print(f"  Average yield: {float(avg_yield):.2f}%")
    print(f"  Std dev:       {float(std_yield):.2f}%")
    print(f"  P5/P95:        {float(p05_yield):.2f}% / {float(p95_yield):.2f}%")
    print(f"  Over-yield (>100%): {over_yield}")

    ok = 95 <= float(avg_yield) <= 100 and over_yield == 0
    v = "PASS" if ok else ("WARN" if over_yield == 0 else "FAIL")
    _kpi_row("Avg Yield", f"{float(avg_yield):.2f}%", "95-100%", v)
    counts[v.lower()] += 1

    # Q3.4 — Production by Plant Distribution
    _q_header("Q3.4", "Production by Plant Distribution")
    with conn.cursor() as cur:
        cur.execute("""
            SELECT b.plant_id, p.name,
                   COUNT(*) as batch_count,
                   SUM(b.quantity_kg) / 1000.0 as total_tons
            FROM batches b
            JOIN plants p ON p.id = b.plant_id
            GROUP BY b.plant_id, p.name
            ORDER BY total_tons DESC
        """)
        plant_rows = cur.fetchall()

    print(f"  {'Plant':<30} {'Batches':>10} {'Tons':>12}")
    print(f"  {'─' * 30} {'─' * 10} {'─' * 12}")
    tons_list = []
    for _pid, pname, bcnt, tons in plant_rows:
        print(f"  {pname:<30} {bcnt:>10,} {float(tons):>12,.0f}")
        tons_list.append(float(tons))

    if tons_list:
        import statistics
        mean_t = statistics.mean(tons_list)
        std_t = statistics.stdev(tons_list) if len(tons_list) > 1 else 0
        cv = std_t / mean_t if mean_t > 0 else 0
        print(f"\n  CV of production (tons): {cv:.2f}")
        v = "PASS" if cv < 0.5 else ("WARN" if cv < 1.0 else "FAIL")
    else:
        v = "FAIL"
    counts[v.lower()] += 1

    # Q3.5 — BOM Integrity (3-Level)
    _q_header("Q3.5", "BOM Integrity — active SKUs with formulas and ingredients")
    with conn.cursor() as cur:
        cur.execute("""
            SELECT COUNT(*) FROM skus s
            WHERE s.is_active = true
              AND NOT EXISTS (SELECT 1 FROM formulas f WHERE f.product_id = s.id)
        """)
        skus_no_formula = cur.fetchone()[0]

        cur.execute("""
            SELECT COUNT(*) FROM formulas f
            WHERE NOT EXISTS (
                SELECT 1 FROM formula_ingredients fi WHERE fi.formula_id = f.id
            )
        """)
        formulas_no_ingredients = cur.fetchone()[0]

    print(f"  Active SKUs without formulas: {skus_no_formula}")
    print(f"  Formulas without ingredients: {formulas_no_ingredients}")

    v = "PASS" if skus_no_formula == 0 and formulas_no_ingredients == 0 else "FAIL"
    _kpi_row("BOM Orphans", f"{skus_no_formula + formulas_no_ingredients}", "0", v)
    counts[v.lower()] += 1

    # Q3.6 — Production/Demand Alignment
    _q_header("Q3.6", "Production/Demand Alignment — FG production vs demand")
    with conn.cursor() as cur:
        cur.execute("""
            SELECT SUM(quantity_kg) FROM batches
            WHERE product_type = 'finished_good'
        """)
        fg_production_kg = cur.fetchone()[0] or 0

        cur.execute("""
            SELECT SUM(ol.quantity_cases * s.weight_kg)
            FROM order_lines ol
            JOIN skus s ON s.id = ol.sku_id
        """)
        demand_kg = cur.fetchone()[0] or 0

    ratio = _f(fg_production_kg) / _f(demand_kg) if _f(demand_kg) > 0 else 0
    print(f"  FG Production: {_f(fg_production_kg) / 1e6:,.1f}M kg")
    print(f"  Demand (order weight): {_f(demand_kg) / 1e6:,.1f}M kg")
    print(f"  Production/Demand ratio: {ratio:.3f}")

    v = _traffic(ratio, 0.95, 1.05, 0.85, 1.15)
    _kpi_row("Prod/Demand Ratio", f"{ratio:.3f}", "0.95-1.05", v)
    counts[v.lower()] += 1

    # Q3.7 — Bulk vs FG Production Mix
    _q_header("Q3.7", "Bulk vs FG Production Mix")
    with conn.cursor() as cur:
        cur.execute("""
            SELECT product_type, COUNT(*), SUM(quantity_kg)
            FROM batches
            GROUP BY product_type
            ORDER BY product_type
        """)
        mix_rows = cur.fetchall()

    types_present = set()
    for ptype, cnt, total_kg in mix_rows:
        types_present.add(ptype or "unknown")
        print(f"  {ptype or 'unknown':<25} {cnt:>10,} batches  {float(total_kg) / 1e6:>10,.1f}M kg")

    has_both = "finished_good" in types_present and "bulk_intermediate" in types_present
    v = "PASS" if has_both else "FAIL"
    _kpi_row("Both Types Present", "Yes" if has_both else "No", "Yes", v)
    counts[v.lower()] += 1

    return counts


# ═══════════════════════════════════════════════════════════════════════════════
# Section 4: SCOR Deliver Process
# ═══════════════════════════════════════════════════════════════════════════════

def run_section4(conn: psycopg2.extensions.connection) -> dict[str, int]:
    """SECTION 4: SCOR Deliver Process (Q4.1-Q4.7)."""
    _section_header(4, "SCOR DELIVER PROCESS")
    counts = _verdict_counts()

    # Q4.1 — Shipment Volume by Route Type
    _q_header("Q4.1", "Shipment Volume by Route Type")
    with conn.cursor() as cur:
        cur.execute("""
            SELECT route_type,
                   COUNT(*) as shipments,
                   SUM(total_weight_kg) as total_kg,
                   SUM(freight_cost) as total_freight
            FROM shipments
            GROUP BY route_type
            ORDER BY shipments DESC
        """)
        route_rows = cur.fetchall()

    print(f"  {'Route Type':<30} {'Shipments':>10} {'Weight (t)':>12} {'Freight':>14}")
    print(f"  {'─' * 30} {'─' * 10} {'─' * 12} {'─' * 14}")
    for rt, cnt, wt, fr in route_rows:
        wt_tons = float(wt or 0) / 1000.0
        print(f"  {rt or 'null':<30} {cnt:>10,} {wt_tons:>12,.0f} {_fmt_money(float(fr or 0)):>14}")

    v = "PASS" if len(route_rows) >= 3 else "WARN"
    print(f"  Verdict: {v} ({len(route_rows)} route types)")
    counts[v.lower()] += 1

    # Q4.2 — Shipment -> AR Invoice Chain
    _q_header("Q4.2", "Shipment -> AR Invoice Chain")
    with conn.cursor() as cur:
        cur.execute("SELECT COUNT(*) FROM shipments")
        n_shipments = cur.fetchone()[0]
        cur.execute("SELECT COUNT(DISTINCT shipment_id) FROM ar_invoices WHERE shipment_id IS NOT NULL")
        n_with_ar = cur.fetchone()[0]

    ar_pct = _pct(n_with_ar, n_shipments)
    print(f"  Total shipments: {n_shipments:,}")
    print(f"  With AR invoice: {n_with_ar:,} ({ar_pct:.1f}%)")
    print("  (Only demand-endpoint shipments generate AR invoices, ~5-10%)")

    v = _traffic(ar_pct, 3, 15, 1, 25)
    _kpi_row("AR/Shipment Rate", f"{ar_pct:.1f}%", "5-10%", v)
    counts[v.lower()] += 1

    # Q4.3 — Freight Cost Coverage
    _q_header("Q4.3", "Freight Cost Coverage — zero/null freight?")
    with conn.cursor() as cur:
        cur.execute("""
            SELECT COUNT(*),
                   COUNT(CASE WHEN freight_cost IS NULL OR freight_cost <= 0 THEN 1 END)
            FROM shipments
        """)
        total_ship, zero_freight = cur.fetchone()

    zero_pct = _pct(zero_freight, total_ship)
    print(f"  Shipments with null/zero freight: {zero_freight:,} ({zero_pct:.1f}%)")

    v = "PASS" if zero_pct < 5 else ("WARN" if zero_pct < 10 else "FAIL")
    _kpi_row("Zero-Freight Rate", f"{zero_pct:.1f}%", "<5%", v)
    counts[v.lower()] += 1

    # Q4.4 — Delivery Lead Time by Echelon
    _q_header("Q4.4", "Delivery Lead Time by Echelon")
    with conn.cursor() as cur:
        cur.execute("""
            SELECT route_type,
                   AVG(arrival_date - ship_date) as avg_lt,
                   percentile_cont(0.50) WITHIN GROUP (ORDER BY arrival_date - ship_date) as p50,
                   percentile_cont(0.95) WITHIN GROUP (ORDER BY arrival_date - ship_date) as p95,
                   COUNT(CASE WHEN arrival_date < ship_date THEN 1 END) as time_travel
            FROM shipments
            WHERE arrival_date IS NOT NULL AND ship_date IS NOT NULL
            GROUP BY route_type
            ORDER BY route_type
        """)
        lt_rows = cur.fetchall()

    total_violations = 0
    print(f"  {'Route Type':<30} {'Avg':>6} {'P50':>6} {'P95':>6} {'Violations':>10}")
    print(f"  {'─' * 30} {'─' * 6} {'─' * 6} {'─' * 6} {'─' * 10}")
    for rt, avg_lt, p50, p95, violations in lt_rows:
        total_violations += violations
        print(f"  {rt or 'null':<30} {float(avg_lt):>6.1f} {float(p50):>6.1f} {float(p95):>6.1f} {violations:>10}")

    v = "PASS" if total_violations == 0 else "FAIL"
    _kpi_row("Time-Travel Violations", str(total_violations), "0", v)
    counts[v.lower()] += 1

    # Q4.5 — Aggregate Fill Rate
    _q_header("Q4.5", "Aggregate Fill Rate")
    with conn.cursor() as cur:
        cur.execute("SELECT SUM(quantity_cases) FROM shipment_lines")
        shipped_cases = cur.fetchone()[0] or 0
        cur.execute("SELECT SUM(quantity_cases) FROM order_lines")
        ordered_cases = cur.fetchone()[0] or 0

    fill_rate = _pct(shipped_cases, ordered_cases)
    print(f"  Shipped cases: {float(shipped_cases):,.0f}")
    print(f"  Ordered cases: {float(ordered_cases):,.0f}")
    print(f"  Fill rate: {fill_rate:.1f}%")

    v = "PASS" if fill_rate > 95 else ("WARN" if fill_rate > 90 else "FAIL")
    _kpi_row("Fill Rate", f"{fill_rate:.1f}%", ">95%", v)
    counts[v.lower()] += 1

    # Q4.6 — Shipment Weight Reasonableness
    _q_header("Q4.6", "Shipment Weight Reasonableness")
    with conn.cursor() as cur:
        cur.execute("""
            SELECT COUNT(*),
                   COUNT(CASE WHEN total_weight_kg > 20000 THEN 1 END),
                   COUNT(CASE WHEN total_weight_kg < 1 AND total_weight_kg IS NOT NULL THEN 1 END)
            FROM shipments
        """)
        n_ship, n_over, n_under = cur.fetchone()

    over_pct = _pct(n_over, n_ship)
    under_pct = _pct(n_under, n_ship)
    print(f"  Overweight (>20t FTL): {n_over:,} ({over_pct:.2f}%)")
    print(f"  Underweight (<1kg):    {n_under:,} ({under_pct:.2f}%)")

    ok = over_pct < 1 and under_pct < 1
    v = "PASS" if ok else ("WARN" if over_pct < 5 and under_pct < 5 else "FAIL")
    _kpi_row("Weight Anomalies", f"{over_pct:.1f}%/{under_pct:.1f}%", "<1% each", v)
    counts[v.lower()] += 1

    # Q4.7 — DC-to-Store Last Mile Coverage
    _q_header("Q4.7", "DC-to-Store Last Mile Coverage")
    with conn.cursor() as cur:
        cur.execute("""
            SELECT COUNT(DISTINCT destination_id)
            FROM shipments
            WHERE route_type LIKE '%store%' OR route_type LIKE '%retail%'
        """)
        stores_served = cur.fetchone()[0]
        cur.execute("SELECT COUNT(*) FROM retail_locations")
        total_stores = cur.fetchone()[0]

    coverage = _pct(stores_served, total_stores)
    print(f"  Stores served: {stores_served:,} / {total_stores:,} ({coverage:.1f}%)")
    print("  (Informational)")
    counts["pass"] += 1

    return counts


# ═══════════════════════════════════════════════════════════════════════════════
# Section 5: SCOR Return Process
# ═══════════════════════════════════════════════════════════════════════════════

def run_section5(conn: psycopg2.extensions.connection) -> dict[str, int]:
    """SECTION 5: SCOR Return Process (Q5.1-Q5.4)."""
    _section_header(5, "SCOR RETURN PROCESS")
    counts = _verdict_counts()

    # Q5.1 — Return Rate
    _q_header("Q5.1", "Return Rate — % of shipped cases returned")
    with conn.cursor() as cur:
        cur.execute("SELECT SUM(quantity_cases) FROM return_lines")
        returned_cases = cur.fetchone()[0] or 0
        cur.execute("SELECT SUM(quantity_cases) FROM shipment_lines")
        shipped_cases = cur.fetchone()[0] or 0

    return_rate = _pct(returned_cases, shipped_cases)
    print(f"  Returned cases: {float(returned_cases):,.0f}")
    print(f"  Shipped cases:  {float(shipped_cases):,.0f}")
    print(f"  Return rate:    {return_rate:.2f}%")

    v = _traffic(return_rate, 1, 5, 0, 10)
    _kpi_row("Return Rate", f"{return_rate:.2f}%", "1-5%", v)
    counts[v.lower()] += 1

    # Q5.2 — Return Condition Distribution
    _q_header("Q5.2", "Return Condition Distribution")
    with conn.cursor() as cur:
        cur.execute("""
            SELECT condition, COUNT(*), SUM(quantity_cases)
            FROM return_lines
            GROUP BY condition
            ORDER BY COUNT(*) DESC
        """)
        cond_rows = cur.fetchall()

    total_lines = sum(_f(r[1]) for r in cond_rows)
    print(f"  {'Condition':<20} {'Lines':>8} {'Cases':>12} {'%':>8}")
    print(f"  {'─' * 20} {'─' * 8} {'─' * 12} {'─' * 8}")
    for cond, cnt, cases in cond_rows:
        print(f"  {cond:<20} {cnt:>8,} {float(cases):>12,.0f} {_pct(cnt, total_lines):>7.1f}%")
    print("  (Informational)")
    counts["pass"] += 1

    # Q5.3 — Disposition Analysis
    _q_header("Q5.3", "Disposition Analysis")
    with conn.cursor() as cur:
        cur.execute("""
            SELECT disposition, COUNT(*), SUM(quantity_cases)
            FROM disposition_logs
            GROUP BY disposition
            ORDER BY COUNT(*) DESC
        """)
        disp_rows = cur.fetchall()

    total_disp = sum(_f(r[1]) for r in disp_rows)
    resale_count = 0
    print(f"  {'Disposition':<20} {'Count':>8} {'Cases':>12} {'%':>8}")
    print(f"  {'─' * 20} {'─' * 8} {'─' * 12} {'─' * 8}")
    for disp, cnt, cases in disp_rows:
        if disp in ("resale", "restock"):
            resale_count += cnt
        print(f"  {disp:<20} {cnt:>8,} {float(cases):>12,.0f} {_pct(cnt, total_disp):>7.1f}%")

    resale_pct = _pct(resale_count, total_disp)
    v = _traffic(resale_pct, 70, 95, 50, 100)
    _kpi_row("Resale/Restock %", f"{resale_pct:.1f}%", "~80%", v)
    counts[v.lower()] += 1

    # Q5.4 — Return -> GL Reconciliation
    _q_header("Q5.4", "Return -> GL Reconciliation — 5200 vs return value")
    with conn.cursor() as cur:
        cur.execute("""
            SELECT SUM(debit_amount) FROM gl_journal WHERE account_code = '5200'
        """)
        gl_returns = cur.fetchone()[0] or 0

        cur.execute("""
            SELECT SUM(rl.quantity_cases * s.price_per_case)
            FROM return_lines rl
            JOIN skus s ON s.id = rl.sku_id
        """)
        calc_returns = cur.fetchone()[0] or 0

    ratio = _f(gl_returns) / _f(calc_returns) if _f(calc_returns) > 0 else 0
    print(f"  GL 5200 (Returns Expense): {_fmt_money(gl_returns)}")
    print(f"  Calculated (qty*price):    {_fmt_money(calc_returns)}")
    print(f"  Ratio: {ratio:.3f}")

    v = "PASS" if 0.80 <= ratio <= 1.20 else ("WARN" if 0.60 <= ratio <= 1.40 else "FAIL")
    _kpi_row("GL/Calc Ratio", f"{ratio:.3f}", "0.80-1.20", v)
    counts[v.lower()] += 1

    return counts


# ═══════════════════════════════════════════════════════════════════════════════
# Section 6: Desmet's Triangle
# ═══════════════════════════════════════════════════════════════════════════════

def run_section6(conn: psycopg2.extensions.connection) -> dict[str, int]:
    """SECTION 6: Desmet's Triangle (Q6.1-Q6.7)."""
    _section_header(6, "DESMET'S TRIANGLE — Service vs Cost vs Cash")
    counts = _verdict_counts()

    # Q6.1 — Service: Fill Rate + Returns
    _q_header("Q6.1", "Service: Fill Rate + Return Rate")
    with conn.cursor() as cur:
        cur.execute("SELECT SUM(quantity_cases) FROM shipment_lines")
        shipped = cur.fetchone()[0] or 0
        cur.execute("SELECT SUM(quantity_cases) FROM order_lines")
        ordered = cur.fetchone()[0] or 0
        cur.execute("SELECT SUM(quantity_cases) FROM return_lines")
        returned = cur.fetchone()[0] or 0

    fill_rate = _pct(shipped, ordered)
    return_rate = _pct(returned, shipped)
    print(f"  Fill Rate:   {fill_rate:.1f}%")
    print(f"  Return Rate: {return_rate:.2f}%")

    ok = fill_rate > 97 and return_rate < 5
    v = "PASS" if ok else ("WARN" if fill_rate > 92 else "FAIL")
    _kpi_row("Service Score", f"{fill_rate:.1f}% / {return_rate:.1f}%", ">97% / <5%", v)
    counts[v.lower()] += 1

    # Q6.2 — Cost: P&L Summary
    _q_header("Q6.2", "Cost: GL-derived P&L Summary")
    with conn.cursor() as cur:
        cur.execute("""
            SELECT
                SUM(CASE WHEN account_code = '4100' THEN credit_amount ELSE 0 END) as revenue,
                SUM(CASE WHEN account_code = '5100' THEN debit_amount ELSE 0 END) as cogs,
                SUM(CASE WHEN account_code = '5300' THEN debit_amount ELSE 0 END) as freight,
                SUM(CASE WHEN account_code = '5200' THEN debit_amount ELSE 0 END) as returns_exp,
                SUM(CASE WHEN account_code = '5400' THEN debit_amount ELSE 0 END) as mfg_overhead,
                SUM(CASE WHEN account_code = '5500' THEN debit_amount ELSE 0 END) as bad_debt
            FROM gl_journal
        """)
        revenue, cogs, freight, returns_exp, mfg_oh, bad_debt = cur.fetchone()

    gross_margin = _f(revenue) - _f(cogs) - _f(freight) - _f(returns_exp) - _f(mfg_oh) - _f(bad_debt)
    margin_pct = _pct(gross_margin, revenue)

    print(f"  Revenue:          {_fmt_money(revenue)}")
    print(f"  COGS:             {_fmt_money(cogs)}")
    print(f"  Freight:          {_fmt_money(freight)}")
    print(f"  Returns Expense:  {_fmt_money(returns_exp)}")
    print(f"  Mfg Overhead:     {_fmt_money(mfg_oh)}")
    print(f"  Bad Debt:         {_fmt_money(bad_debt)}")
    print("  ────────────────────────────────")
    print(f"  Gross Margin:     {_fmt_money(gross_margin)} ({margin_pct:.1f}%)")

    v = _traffic(margin_pct, 10, 40, 0, 50)
    _kpi_row("Gross Margin", f"{margin_pct:.1f}%", "10-40%", v)
    counts[v.lower()] += 1

    # Q6.3 — Cost: Freight % of Revenue
    _q_header("Q6.3", "Cost: Freight as % of Revenue")
    freight_pct = _pct(freight, revenue)
    print(f"  Freight / Revenue: {freight_pct:.2f}%")

    v = "PASS" if freight_pct < 10 else ("WARN" if freight_pct < 15 else "FAIL")
    _kpi_row("Freight %", f"{freight_pct:.2f}%", "<10%", v)
    counts[v.lower()] += 1

    # Q6.4 — Cash: DSO
    _q_header("Q6.4", "Cash: DSO — Days Sales Outstanding")
    with conn.cursor() as cur:
        cur.execute("""
            SELECT AVG(r.receipt_date - ai.invoice_date),
                   percentile_cont(0.50) WITHIN GROUP (ORDER BY r.receipt_date - ai.invoice_date)
            FROM ar_receipts r
            JOIN ar_invoices ai ON ai.id = r.invoice_id
        """)
        avg_dso, p50_dso = cur.fetchone()

    if avg_dso is not None:
        print(f"  Average DSO: {float(avg_dso):.1f} days")
        print(f"  Median DSO:  {float(p50_dso):.1f} days")
        v = _traffic(float(avg_dso), 15, 45, 5, 60)
        _kpi_row("DSO", f"{float(avg_dso):.1f}d", "15-45d", v)
    else:
        print("  No AR receipts found")
        v = "FAIL"
    counts[v.lower()] += 1

    # Q6.5 — Cash: DPO
    _q_header("Q6.5", "Cash: DPO — Days Payable Outstanding")
    with conn.cursor() as cur:
        cur.execute("""
            SELECT AVG(p.payment_date - ai.invoice_date)
            FROM ap_payments p
            JOIN ap_invoices ai ON ai.id = p.invoice_id
        """)
        avg_dpo = cur.fetchone()[0]

    if avg_dpo is not None:
        print(f"  Average DPO: {float(avg_dpo):.1f} days")
        v = "PASS" if abs(float(avg_dpo) - DPO_TARGET) <= 10 else "WARN"
        _kpi_row("DPO", f"{float(avg_dpo):.1f}d", f"{DPO_TARGET:.0f}d +-10", v)
    else:
        print("  No AP payments found")
        v = "FAIL"
    counts[v.lower()] += 1

    # Q6.6 — Cash: DIO (inventory sampled weekly)
    _q_header("Q6.6", "Cash: DIO — Days Inventory Outstanding")
    with conn.cursor() as cur:
        # Sample weekly for performance (inventory 130M+ rows)
        cur.execute("""
            SELECT AVG(daily_qty)
            FROM (
                SELECT day, SUM(quantity_cases) as daily_qty
                FROM inventory
                WHERE MOD(day, 7) = 0
                GROUP BY day
            ) weekly
        """)
        avg_inv_cases = cur.fetchone()[0] or 0

        cur.execute("""
            SELECT SUM(CASE WHEN account_code = '5100' THEN debit_amount ELSE 0 END)
            FROM gl_journal
        """)
        total_cogs = cur.fetchone()[0] or 0

        cur.execute("SELECT MAX(day) - MIN(day) + 1 FROM orders")
        sim_days = cur.fetchone()[0] or 365

    daily_cogs = _f(total_cogs) / sim_days if sim_days > 0 else 1

    # Convert inventory cases to $ using avg cost_per_case
    with conn.cursor() as cur:
        cur.execute("SELECT AVG(cost_per_case) FROM skus WHERE cost_per_case > 0")
        avg_cost = float(cur.fetchone()[0] or 1)

    inv_value = float(avg_inv_cases) * avg_cost
    dio = inv_value / daily_cogs if daily_cogs > 0 else 0

    print(f"  Avg weekly inventory: {float(avg_inv_cases):,.0f} cases (${inv_value:,.0f})")
    print(f"  Daily COGS run rate: {_fmt_money(daily_cogs)}")
    print(f"  DIO: {dio:.1f} days")

    v = _traffic(dio, 20, 60, 10, 90)
    _kpi_row("DIO", f"{dio:.1f}d", "20-60d", v)
    counts[v.lower()] += 1

    # Q6.7 — Cash: Cash-to-Cash Cycle
    _q_header("Q6.7", "Cash: Cash-to-Cash Cycle — DSO + DIO - DPO")
    dso_val = float(avg_dso) if avg_dso is not None else 30.0
    dpo_val = float(avg_dpo) if avg_dpo is not None else DPO_TARGET
    c2c = dso_val + dio - dpo_val

    print(f"  DSO: {dso_val:.1f}d + DIO: {dio:.1f}d - DPO: {dpo_val:.1f}d = {c2c:.1f}d")

    v = _traffic(c2c, 10, 30, -10, 60)
    _kpi_row("Cash-to-Cash", f"{c2c:.1f}d", "10-30d", v)
    counts[v.lower()] += 1

    return counts


# ═══════════════════════════════════════════════════════════════════════════════
# Section 7: Temporal & Causal Integrity
# ═══════════════════════════════════════════════════════════════════════════════

def run_section7(conn: psycopg2.extensions.connection) -> dict[str, int]:
    """SECTION 7: Temporal & Causal Integrity (Q7.1-Q7.6)."""
    _section_header(7, "TEMPORAL & CAUSAL INTEGRITY")
    counts = _verdict_counts()

    # Q7.1 — Sequence Monotonicity
    _q_header("Q7.1", "Sequence Monotonicity — no backward jumps in seq_id")
    seq_tables = [
        ("orders", "id", "transaction_sequence_id"),
        ("shipments", "id", "transaction_sequence_id"),
        ("batches", "id", "transaction_sequence_id"),
        ("gl_journal", "id", "transaction_sequence_id"),
    ]
    all_ok = True
    for tbl, pk, seq_col in seq_tables:
        with conn.cursor() as cur:
            cur.execute(f"""
                SELECT COUNT(*) FROM (
                    SELECT {seq_col},
                           LAG({seq_col}) OVER (ORDER BY {pk}) as prev_val
                    FROM {tbl}
                ) sub
                WHERE {seq_col} < prev_val
            """)
            violations = cur.fetchone()[0]
        status = "OK" if violations == 0 else f"VIOLATIONS: {violations:,}"
        if violations > 0:
            all_ok = False
        print(f"  {tbl}: {status}")

    v = "PASS" if all_ok else "FAIL"
    print(f"  Verdict: {v}")
    counts[v.lower()] += 1

    # Q7.2 — No Payments Before Invoices
    _q_header("Q7.2", "No Payments Before Invoices")
    with conn.cursor() as cur:
        # AP side
        cur.execute("""
            SELECT COUNT(*) FROM ap_payments p
            JOIN ap_invoices ai ON ai.id = p.invoice_id
            WHERE p.payment_date < ai.invoice_date
        """)
        ap_violations = cur.fetchone()[0]

        # AR side
        cur.execute("""
            SELECT COUNT(*) FROM ar_receipts r
            JOIN ar_invoices ai ON ai.id = r.invoice_id
            WHERE r.receipt_date < ai.invoice_date
        """)
        ar_violations = cur.fetchone()[0]

    total_v = ap_violations + ar_violations
    print(f"  AP payments before invoice: {ap_violations}")
    print(f"  AR receipts before invoice: {ar_violations}")

    v = "PASS" if total_v == 0 else "FAIL"
    _kpi_row("Pre-Invoice Payments", str(total_v), "0", v)
    counts[v.lower()] += 1

    # Q7.3 — No Arrivals Before Dispatches
    _q_header("Q7.3", "No Arrivals Before Dispatches")
    with conn.cursor() as cur:
        cur.execute("""
            SELECT COUNT(*) FROM shipments
            WHERE arrival_date IS NOT NULL AND arrival_date < ship_date
        """)
        time_travel = cur.fetchone()[0]

    print(f"  Arrivals before ship_date: {time_travel}")

    v = "PASS" if time_travel == 0 else "FAIL"
    _kpi_row("Time-Travel Shipments", str(time_travel), "0", v)
    counts[v.lower()] += 1

    # Q7.4 — GR -> AP Invoice Date Ordering
    _q_header("Q7.4", "GR -> AP Invoice Date Ordering")
    with conn.cursor() as cur:
        cur.execute("""
            SELECT COUNT(*) FROM ap_invoices ai
            JOIN goods_receipts gr ON gr.id = ai.gr_id
            WHERE ai.invoice_date < gr.receipt_date
        """)
        gr_ap_violations = cur.fetchone()[0]

    print(f"  AP invoice before GR receipt: {gr_ap_violations}")

    v = "PASS" if gr_ap_violations == 0 else ("WARN" if gr_ap_violations < 10 else "FAIL")
    _kpi_row("GR→AP Violations", str(gr_ap_violations), "0", v)
    counts[v.lower()] += 1

    # Q7.5 — GL Dates Within Sim Range
    _q_header("Q7.5", "GL Dates Within Sim Range")
    with conn.cursor() as cur:
        cur.execute("SELECT MIN(entry_date), MAX(entry_date) FROM gl_journal")
        gl_min, gl_max = cur.fetchone()

        cur.execute("""
            SELECT COUNT(*) FROM gl_journal
            WHERE entry_date < 1 OR entry_date > 456
        """)
        out_of_range = cur.fetchone()[0]

    print(f"  GL date range: day {gl_min} to {gl_max}")
    print(f"  Out of range (outside 1-455): {out_of_range}")

    v = "PASS" if out_of_range == 0 else "FAIL"
    _kpi_row("Out-of-Range GL", str(out_of_range), "0", v)
    counts[v.lower()] += 1

    # Q7.6 — Cross-Chain Date Consistency
    _q_header("Q7.6", "Cross-Chain Date Consistency — PO->GR, GR->AP, AP->Payment all forward")
    with conn.cursor() as cur:
        # GR receipt_date >= PO order_date (via plant match)
        cur.execute("""
            SELECT COUNT(*) FROM goods_receipts gr
            JOIN purchase_orders po ON po.plant_id = gr.plant_id
                AND po.order_date <= gr.receipt_date
                AND gr.receipt_date <= po.order_date + 30
            WHERE gr.receipt_date < po.order_date
        """)
        po_gr_back = cur.fetchone()[0]

        # AP payment_date >= AP invoice_date (already checked in Q7.2, reuse)
        # AP invoice_date >= GR receipt_date (already checked in Q7.4, reuse)
        total_back = po_gr_back + gr_ap_violations + ap_violations

    print(f"  PO→GR backward: {po_gr_back}")
    print(f"  GR→AP backward: {gr_ap_violations}")
    print(f"  AP→Payment backward: {ap_violations}")

    v = "PASS" if total_back == 0 else ("WARN" if total_back < 10 else "FAIL")
    _kpi_row("Total Backward", str(total_back), "<1%", v)
    counts[v.lower()] += 1

    return counts


# ═══════════════════════════════════════════════════════════════════════════════
# Section 8: Friction Layer Audit
# ═══════════════════════════════════════════════════════════════════════════════

def run_section8(conn: psycopg2.extensions.connection) -> dict[str, int]:
    """SECTION 8: Friction Layer Audit (Q8.1-Q8.7)."""
    _section_header(8, "FRICTION LAYER AUDIT")
    counts = _verdict_counts()

    # Q8.1 — Duplicate Suppliers
    _q_header("Q8.1", "Duplicate Suppliers — '-ALT' suffix rate")
    with conn.cursor() as cur:
        cur.execute("SELECT COUNT(*) FROM suppliers")
        total_suppliers = cur.fetchone()[0]
        cur.execute("SELECT COUNT(*) FROM suppliers WHERE supplier_code LIKE '%-ALT'")
        dup_suppliers = cur.fetchone()[0]

    # Rate = duplicates / (total - duplicates) since duplicates were added
    base_suppliers = total_suppliers - dup_suppliers
    dup_rate = dup_suppliers / base_suppliers if base_suppliers > 0 else 0

    print(f"  Total suppliers: {total_suppliers}")
    print(f"  '-ALT' duplicates: {dup_suppliers}")
    print(f"  Effective rate: {dup_rate:.3f} (expected {EXPECTED_FRICTION['duplicate_supplier_rate']:.2f})")

    v = _friction_verdict(dup_rate, EXPECTED_FRICTION["duplicate_supplier_rate"])
    _kpi_row("Dup Supplier Rate", f"{dup_rate * 100:.1f}%", "~10%", v)
    counts[v.lower()] += 1

    # Q8.2 — SKU Rename Chains
    _q_header("Q8.2", "SKU Rename Chains — '-OLD' suffix + supersedes_sku_id")
    with conn.cursor() as cur:
        cur.execute("SELECT COUNT(*) FROM skus")
        total_skus = cur.fetchone()[0]
        cur.execute("SELECT COUNT(*) FROM skus WHERE sku_code LIKE '%-OLD'")
        old_skus = cur.fetchone()[0]
        cur.execute("SELECT COUNT(*) FROM skus WHERE supersedes_sku_id IS NOT NULL")
        supersedes_count = cur.fetchone()[0]

    base_skus = total_skus - old_skus
    rename_rate = old_skus / base_skus if base_skus > 0 else 0

    print(f"  Total SKUs: {total_skus}")
    print(f"  '-OLD' SKUs: {old_skus}")
    print(f"  With supersedes_sku_id: {supersedes_count}")
    print(f"  Effective rate: {rename_rate:.3f} (expected {EXPECTED_FRICTION['sku_rename_rate']:.2f})")

    v = _friction_verdict(rename_rate, EXPECTED_FRICTION["sku_rename_rate"])
    _kpi_row("SKU Rename Rate", f"{rename_rate * 100:.1f}%", "~5%", v)
    counts[v.lower()] += 1

    # Q8.3 — Invoice Variance Rates
    _q_header("Q8.3", "Invoice Variance Rates — price and qty")
    with conn.cursor() as cur:
        cur.execute("SELECT COUNT(*) FROM ap_invoice_lines")
        n_lines = cur.fetchone()[0]
        cur.execute("""
            SELECT variance_type, COUNT(*)
            FROM invoice_variances
            GROUP BY variance_type
        """)
        var_rows = {r[0]: r[1] for r in cur.fetchall()}

    price_count = var_rows.get("price", 0)
    qty_count = var_rows.get("qty", 0)
    price_rate = price_count / n_lines if n_lines > 0 else 0
    qty_rate = qty_count / n_lines if n_lines > 0 else 0

    print(f"  AP invoice lines: {n_lines:,}")
    print(f"  Price variances: {price_count:,} ({price_rate * 100:.2f}%)")
    print(f"  Qty variances: {qty_count:,} ({qty_rate * 100:.2f}%)")

    v_price = _friction_verdict(price_rate, EXPECTED_FRICTION["price_variance_rate"])
    v_qty = _friction_verdict(qty_rate, EXPECTED_FRICTION["qty_variance_rate"])
    _kpi_row("Price Variance Rate", f"{price_rate * 100:.2f}%", "~8%", v_price)
    _kpi_row("Qty Variance Rate", f"{qty_rate * 100:.2f}%", "~5%", v_qty)
    counts[v_price.lower()] += 1
    counts[v_qty.lower()] += 1

    # Q8.4 — Bad Debt Rate
    _q_header("Q8.4", "Bad Debt Rate — AR invoices without receipts")
    with conn.cursor() as cur:
        cur.execute("SELECT COUNT(*) FROM ar_invoices")
        n_ar = cur.fetchone()[0]
        cur.execute("""
            SELECT COUNT(*) FROM ar_invoices ai
            WHERE NOT EXISTS (SELECT 1 FROM ar_receipts r WHERE r.invoice_id = ai.id)
        """)
        n_unpaid = cur.fetchone()[0]

        cur.execute("""
            SELECT COUNT(*) FROM gl_journal WHERE reference_type = 'bad_debt'
        """)
        n_bd_gl = cur.fetchone()[0]

    bd_rate = n_unpaid / n_ar if n_ar > 0 else 0

    print(f"  AR invoices: {n_ar:,}")
    print(f"  Without receipts: {n_unpaid:,}")
    print(f"  GL bad_debt entries: {n_bd_gl:,}")
    print(f"  Bad debt rate: {bd_rate * 100:.3f}%")

    v = _friction_verdict(bd_rate, EXPECTED_FRICTION["bad_debt_rate"], tol=0.003)
    _kpi_row("Bad Debt Rate", f"{bd_rate * 100:.3f}%", "~0.5%", v)
    counts[v.lower()] += 1

    # Q8.5 — Early Payment Discounts
    _q_header("Q8.5", "Early Payment Discounts")
    with conn.cursor() as cur:
        cur.execute("SELECT COUNT(*) FROM ap_payments")
        n_payments = cur.fetchone()[0]
        cur.execute("SELECT COUNT(*) FROM ap_payments WHERE discount_amount > 0")
        n_discounted = cur.fetchone()[0]

    disc_rate = n_discounted / n_payments if n_payments > 0 else 0

    print(f"  AP payments: {n_payments:,}")
    print(f"  With discount: {n_discounted:,}")
    print(f"  Discount rate: {disc_rate * 100:.1f}%")

    v = _friction_verdict(disc_rate, EXPECTED_FRICTION["early_discount_rate"], tol=0.03)
    _kpi_row("Discount Rate", f"{disc_rate * 100:.1f}%", "~10%", v)
    counts[v.lower()] += 1

    # Q8.6 — Null FK Rates
    _q_header("Q8.6", "Null FK Rates — AP gr_id and GL node_id")
    with conn.cursor() as cur:
        cur.execute("SELECT COUNT(*), COUNT(CASE WHEN gr_id IS NULL THEN 1 END) FROM ap_invoices")
        n_ap, n_null_gr = cur.fetchone()
        cur.execute("""
            SELECT COUNT(*),
                   COUNT(CASE WHEN node_id IS NULL OR TRIM(node_id) = '' THEN 1 END)
            FROM gl_journal
        """)
        n_gl, n_null_node = cur.fetchone()

    ap_null_rate = n_null_gr / n_ap if n_ap > 0 else 0
    gl_null_rate = n_null_node / n_gl if n_gl > 0 else 0

    print(f"  AP null gr_id: {n_null_gr:,} / {n_ap:,} ({ap_null_rate * 100:.2f}%)")
    print(f"  GL null/empty node_id: {n_null_node:,} / {n_gl:,} ({gl_null_rate * 100:.2f}%)")

    v_ap = _friction_verdict(ap_null_rate, EXPECTED_FRICTION["null_fk_rate_ap"])
    # GL null rate is higher because treasury events legitimately have empty node_id
    # Just check AP here
    _kpi_row("AP Null FK Rate", f"{ap_null_rate * 100:.2f}%", "~2%", v_ap)
    counts[v_ap.lower()] += 1

    # Q8.7 — Duplicate Invoices with Lines
    _q_header("Q8.7", "Duplicate Invoices — '-DUP' suffix + line items")
    with conn.cursor() as cur:
        cur.execute("SELECT COUNT(*) FROM ap_invoices WHERE invoice_number LIKE '%-DUP'")
        n_dup = cur.fetchone()[0]

        # Non-DUP AP invoices count as the base
        n_base_ap = n_ap - n_dup
        dup_rate = n_dup / n_base_ap if n_base_ap > 0 else 0

        cur.execute("""
            SELECT COUNT(*) FROM ap_invoices ai
            WHERE ai.invoice_number LIKE '%-DUP'
              AND EXISTS (SELECT 1 FROM ap_invoice_lines ail WHERE ail.invoice_id = ai.id)
        """)
        n_dup_with_lines = cur.fetchone()[0]

    print(f"  DUP invoices: {n_dup:,} ({dup_rate * 100:.3f}%)")
    print(f"  DUP with lines: {n_dup_with_lines:,} / {n_dup:,}")

    all_have_lines = n_dup_with_lines == n_dup
    v_rate = _friction_verdict(dup_rate, EXPECTED_FRICTION["duplicate_invoice_rate"], tol=0.003)
    v_lines = "PASS" if all_have_lines else "FAIL"

    _kpi_row("DUP Invoice Rate", f"{dup_rate * 100:.3f}%", "~0.5%", v_rate)
    _kpi_row("DUP Have Lines", f"{n_dup_with_lines}/{n_dup}", "100%", v_lines)
    counts[v_rate.lower()] += 1
    counts[v_lines.lower()] += 1

    return counts


# ═══════════════════════════════════════════════════════════════════════════════
# Section 9: Digital Thread & Traceability
# ═══════════════════════════════════════════════════════════════════════════════

def run_section9(conn: psycopg2.extensions.connection) -> dict[str, int]:
    """SECTION 9: Digital Thread & Traceability (Q9.1-Q9.5)."""
    _section_header(9, "DIGITAL THREAD & TRACEABILITY")
    counts = _verdict_counts()

    # Q9.1 — GL reference_id Coverage
    _q_header("Q9.1", "GL reference_id Coverage by reference_type")
    with conn.cursor() as cur:
        cur.execute("""
            SELECT reference_type,
                   COUNT(*) as total,
                   COUNT(CASE WHEN reference_id IS NOT NULL AND reference_id != '' THEN 1 END) as has_ref
            FROM gl_journal
            GROUP BY reference_type
            ORDER BY reference_type
        """)
        ref_rows = cur.fetchall()

    physical_types = {"goods_receipt", "production", "shipment", "freight", "sale", "return"}
    all_ok = True
    print(f"  {'Reference Type':<22} {'Total':>10} {'Has Ref':>10} {'%':>8}")
    print(f"  {'─' * 22} {'─' * 10} {'─' * 10} {'─' * 8}")
    for rtype, total, has_ref in ref_rows:
        pct = _pct(has_ref, total)
        flag = ""
        if rtype in physical_types and pct < 99:
            all_ok = False
            flag = " LOW"
        print(f"  {rtype:<22} {total:>10,} {has_ref:>10,} {pct:>7.1f}%{flag}")

    v = "PASS" if all_ok else "FAIL"
    print(f"  Verdict: {v} (physical events >=99%)")
    counts[v.lower()] += 1

    # Q9.2 — GL node_id Coverage
    _q_header("Q9.2", "GL node_id Coverage by reference_type")
    with conn.cursor() as cur:
        cur.execute("""
            SELECT reference_type,
                   COUNT(*) as total,
                   COUNT(CASE WHEN node_id IS NOT NULL AND TRIM(node_id) != '' THEN 1 END) as has_node
            FROM gl_journal
            GROUP BY reference_type
            ORDER BY reference_type
        """)
        node_rows = cur.fetchall()

    treasury_types = {"payment", "receipt", "bad_debt"}
    all_ok = True
    print(f"  {'Reference Type':<22} {'Total':>10} {'Has Node':>10} {'%':>8}")
    print(f"  {'─' * 22} {'─' * 10} {'─' * 10} {'─' * 8}")
    for rtype, total, has_node in node_rows:
        pct = _pct(has_node, total)
        if rtype in physical_types and pct < 95:
            all_ok = False
        # Treasury types should have ~0%
        if rtype in treasury_types and pct > 1:
            all_ok = False
        label = "treasury" if rtype in treasury_types else ""
        print(f"  {rtype:<22} {total:>10,} {has_node:>10,} {pct:>7.1f}% {label}")

    v = "PASS" if all_ok else "WARN"
    print(f"  Verdict: {v} (physical >=95%, treasury ~0%)")
    counts[v.lower()] += 1

    # Q9.3 — SKU -> Batch -> Ingredients -> Supplier Chain (10 samples)
    _q_header("Q9.3", "SKU -> Batch -> Ingredients -> Supplier Chain (10 samples)")
    with conn.cursor() as cur:
        cur.execute("""
            SELECT b.id, b.batch_number, b.product_id
            FROM batches b
            WHERE b.product_type = 'finished_good'
            ORDER BY b.id
            LIMIT 10
        """)
        sample_batches = cur.fetchall()

    broken = 0
    for bid, bnum, _prod_id in sample_batches:
        with conn.cursor() as cur:
            cur.execute("""
                SELECT bi.ingredient_id, i.name, si.supplier_id, s.name as supplier_name
                FROM batch_ingredients bi
                JOIN ingredients i ON i.id = bi.ingredient_id
                LEFT JOIN supplier_ingredients si ON si.ingredient_id = bi.ingredient_id
                LEFT JOIN suppliers s ON s.id = si.supplier_id
                WHERE bi.batch_id = %s
                LIMIT 3
            """, (bid,))
            chain_rows = cur.fetchall()

        has_chain = all(r[2] is not None for r in chain_rows) if chain_rows else False
        if not has_chain:
            broken += 1
        status = "OK" if has_chain else "BROKEN"
        print(f"  Batch {bnum}: {len(chain_rows)} ingredients, chain [{status}]")

    v = "PASS" if broken == 0 else ("WARN" if broken <= 2 else "FAIL")
    _kpi_row("Broken Chains", f"{broken}/10", "0", v)
    counts[v.lower()] += 1

    # Q9.4 — Shipment -> GL Traceability (100 samples)
    _q_header("Q9.4", "Shipment -> GL Traceability (100 samples)")
    with conn.cursor() as cur:
        cur.execute("""
            SELECT s.shipment_number
            FROM shipments s
            ORDER BY s.id
            LIMIT 100
        """)
        sample_shipments = [r[0] for r in cur.fetchall()]

        if sample_shipments:
            cur.execute("""
                SELECT reference_id, COUNT(*)
                FROM gl_journal
                WHERE reference_id = ANY(%s)
                GROUP BY reference_id
            """, (sample_shipments,))
            gl_matches = {r[0]: r[1] for r in cur.fetchall()}

    matched = sum(1 for sn in sample_shipments if sn in gl_matches)
    match_pct = _pct(matched, len(sample_shipments))
    print(f"  Sampled: {len(sample_shipments)} shipments")
    print(f"  Found in GL: {matched} ({match_pct:.0f}%)")

    v = "PASS" if match_pct == 100 else ("WARN" if match_pct >= 95 else "FAIL")
    _kpi_row("GL Match Rate", f"{match_pct:.0f}%", "100%", v)
    counts[v.lower()] += 1

    # Q9.5 — Full Procurement Chain (50 samples)
    _q_header("Q9.5", "Full Procurement Chain — GR -> AP -> Payment (50 samples)")
    with conn.cursor() as cur:
        cur.execute("""
            SELECT gr.id, gr.gr_number
            FROM goods_receipts gr
            ORDER BY gr.id
            LIMIT 50
        """)
        sample_grs = cur.fetchall()

    complete = 0
    for grid, _gr_num in sample_grs:
        with conn.cursor() as cur:
            cur.execute("""
                SELECT ai.id, p.id
                FROM ap_invoices ai
                LEFT JOIN ap_payments p ON p.invoice_id = ai.id
                WHERE ai.gr_id = %s
                LIMIT 1
            """, (grid,))
            chain = cur.fetchone()

        has_chain = chain is not None and chain[1] is not None
        if has_chain:
            complete += 1

    complete_pct = _pct(complete, len(sample_grs))
    print(f"  Sampled: {len(sample_grs)} goods receipts")
    print(f"  Complete chain (GR→AP→Payment): {complete} ({complete_pct:.0f}%)")
    print("  (Some AP invoices have null gr_id due to friction)")

    v = "PASS" if complete_pct > 95 else ("WARN" if complete_pct > 85 else "FAIL")
    _kpi_row("Chain Completeness", f"{complete_pct:.0f}%", ">95%", v)
    counts[v.lower()] += 1

    return counts


# ═══════════════════════════════════════════════════════════════════════════════
# Main
# ═══════════════════════════════════════════════════════════════════════════════

def main() -> int:
    parser = argparse.ArgumentParser(
        description="ERP Database Diagnostic — 52 Questions, 10 Sections"
    )
    parser.add_argument(
        "--connection", type=str,
        default="dbname=erp_db",
        help="PostgreSQL connection string (default: dbname=erp_db)",
    )
    parser.add_argument(
        "--section", type=int, default=-1,
        help="Run only a specific section (0-9)",
    )
    args = parser.parse_args()

    # Connect
    try:
        conn = psycopg2.connect(args.connection)
        conn.set_session(readonly=True, autocommit=True)
    except psycopg2.OperationalError as e:
        print(f"ERROR: Cannot connect to database: {e}")
        return 1

    # Tee stdout to file
    stamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    tee_buf = io.StringIO()
    _real_stdout = sys.stdout

    class _Tee:
        def write(self, s: str) -> int:
            _real_stdout.write(s)
            tee_buf.write(s)
            return len(s)
        def flush(self) -> None:
            _real_stdout.flush()

    sys.stdout = _Tee()

    t0 = time.time()

    print("=" * WIDTH)
    print("  ERP DATABASE DIAGNOSTIC (v0.79.0)".center(WIDTH))
    print("  52 Questions — A Consultant's Engagement Workbook".center(WIDTH))
    print("=" * WIDTH)
    print(f"\n  Connection: {args.connection}")
    print(f"  Mode: {'ALL SECTIONS' if args.section == -1 else f'SECTION {args.section} ONLY'}")

    totals = _verdict_counts()

    section_runners: list[tuple[int, str, object]] = [
        (0, "Data Landscape", run_section0),
        (1, "Physical-Financial Reconciliation", run_section1),
        (2, "SCOR Source Process", run_section2),
        (3, "SCOR Make Process", run_section3),
        (4, "SCOR Deliver Process", run_section4),
        (5, "SCOR Return Process", run_section5),
        (6, "Desmet's Triangle", run_section6),
        (7, "Temporal & Causal Integrity", run_section7),
        (8, "Friction Layer Audit", run_section8),
        (9, "Digital Thread & Traceability", run_section9),
    ]

    for sec_num, _sec_name, runner_fn in section_runners:
        if args.section not in (-1, sec_num):
            continue
        t_sec = time.time()
        try:
            result = runner_fn(conn)  # type: ignore[operator]
            totals = _merge(totals, result)
            elapsed_sec = time.time() - t_sec
            print(f"\n  Section {sec_num} complete: {result['pass']}P / {result['warn']}W / {result['fail']}F ({elapsed_sec:.1f}s)")
        except Exception as e:
            print(f"\n  Section {sec_num} ERROR: {e}")
            totals["fail"] += 1

    # Summary
    elapsed = time.time() - t0
    total_q = totals["pass"] + totals["warn"] + totals["fail"]

    print(f"\n{'=' * WIDTH}")
    print("  DIAGNOSTIC COMPLETE".center(WIDTH))
    print(f"{'=' * WIDTH}")
    print(f"\n  Total:    {total_q} questions evaluated in {elapsed:.0f}s")
    print(f"  PASS:     {totals['pass']}")
    print(f"  WARN:     {totals['warn']}")
    print(f"  FAIL:     {totals['fail']}")

    verdict = "PASS" if totals["fail"] == 0 and totals["warn"] <= 3 else (
        "WARN" if totals["fail"] <= 2 else "FAIL"
    )
    print(f"\n  Overall Verdict: {verdict}")
    print()

    # Flush tee
    sys.stdout = _real_stdout
    report_text = tee_buf.getvalue()

    # Save report to file next to script
    from pathlib import Path
    report_dir = Path("data/output/diagnostics")
    report_dir.mkdir(parents=True, exist_ok=True)
    report_path = report_dir / f"diagnose_erp_database_{stamp}.txt"
    report_path.write_text(report_text)
    print(f"Report saved to: {report_path}")

    conn.close()
    return 0 if totals["fail"] == 0 else 1


if __name__ == "__main__":
    raise SystemExit(main())
